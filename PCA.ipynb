{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###  PCA (Principal Component Analysis)\n",
        "**Principal Component Analysis (PCA)** is a **statistical and machine learning technique** used to **reduce the number of features (dimensions)** in a dataset while **preserving as much information (variance) as possible**\n",
        "It is mainly used when data has **many features**, which makes models slow, complex, or noisy.\n",
        "\n"
      ],
      "metadata": {
        "id": "VeapePOoHXdz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PCA on Tips iris**"
      ],
      "metadata": {
        "id": "EkKK8R1wNiQo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBWrDvZHFbgb"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.datasets import load_iris\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# load iris data\n",
        "iris = load_iris()\n",
        "\n",
        "\n",
        "# call PCA\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# fit and transform the data\n",
        "iris_pca = pca.fit_transform(iris.data)\n",
        "\n",
        "# now we can plot the first two principle commponent\n",
        "plt.scatter(iris_pca[:,0], iris_pca[:,1], c=iris.target)\n",
        "plt.xlabel('First Principle Component')\n",
        "plt.ylabel('Second Principle Component')\n",
        "plt.title('PCA of Iris Dataset')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PCA on Tips Data**"
      ],
      "metadata": {
        "id": "ISSDgfTaKZkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# load dataset\n",
        "df = sns.load_dataset('tips')\n",
        "\n",
        "# preprocessing\n",
        "# encode the categorical data\n",
        "le = LabelEncoder()\n",
        "cat_feature = df.select_dtypes(include=['category']).columns\n",
        "for col in cat_feature:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# standardize the data\n",
        "scaler = StandardScaler()\n",
        "df_scaled = scaler.fit_transform(df)\n",
        "\n",
        "# call PCA\n",
        "pca = PCA()\n",
        "\n",
        "# fit and transform the data\n",
        "df_pca = pca.fit_transform(df_scaled)\n",
        "\n",
        "\n",
        "# plot the explained variance ratio\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel('Cumulative explained variance')\n",
        "plt.show()\n",
        "\n",
        "# create a DataFrame to show the loadings\n",
        "loadings = pd.DataFrame(\n",
        "    pca.components_.T,\n",
        "    columns=[f\"PC{i+1}\" for i in range(df_pca.shape[1])],\n",
        "    index=df.columns\n",
        ")\n",
        "print(loadings)\n"
      ],
      "metadata": {
        "id": "DOdjNnBhH8f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the tips dataset from seaborn\n",
        "tips = sns.load_dataset('tips')\n",
        "\n",
        "# Prepare the data for PCA\n",
        "X = tips[['total_bill', 'tip', 'size']]\n",
        "\n",
        "# Standardize the data\n",
        "X = (X - X.mean()) / X.std()\n",
        "\n",
        "# Perform PCA with two components\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(X)\n",
        "\n",
        "# Transform the data into the principal component space\n",
        "X_pca = pca.transform(X)\n",
        "\n",
        "# Add the principal components to the dataset\n",
        "tips['PC1'] = X_pca[:, 0]\n",
        "tips['PC2'] = X_pca[:, 1]\n",
        "\n",
        "# Plot the data in the principal component space\n",
        "sns.scatterplot(x='PC1', y='PC2', data=tips, hue='sex', style='smoker')\n",
        "\n",
        "# Add arrows indicating the direction and strength of each original feature in the principal component space\n",
        "features = pca.components_.T\n",
        "for i, feature in enumerate(features):\n",
        "    plt.arrow(0, 0, feature[0], feature[1], color='black', alpha=0.5, width=0.1,\n",
        "              head_width=0.3, head_length=0.3, length_includes_head=True)\n",
        "    plt.text(feature[0]*1.2, feature[1]*1.2, X.columns[i], color='black', ha='center', va='center', fontsize=12)\n",
        "\n",
        "# Set the axis limits\n",
        "plt.xlim(-3, 3)\n",
        "plt.ylim(-3, 3)\n",
        "\n",
        "# Set the axis labels\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NesIOnAhQn38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the tips dataset from seaborn\n",
        "tips = sns.load_dataset('tips')\n",
        "\n",
        "# Prepare the data for PCA\n",
        "X = tips[['total_bill', 'tip', 'size']]\n",
        "X = (X - X.mean()) / X.std()\n",
        "\n",
        "# Perform PCA with two components\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(X)\n",
        "\n",
        "# Add arrows indicating the direction and strength of each original feature in the principal component space\n",
        "features = pca.components_.T\n",
        "for i, feature in enumerate(features):\n",
        "    x, y = feature\n",
        "    color = 'red' if x > 0 and y > 0 else 'green' if x < 0 and y < 0 else 'blue' if x < 0 and y > 0 else 'purple'\n",
        "    plt.arrow(0, 0, x, y, color=color, alpha=0.5, width=0.1,\n",
        "              head_width=0.3, head_length=0.3, length_includes_head=True)\n",
        "    plt.text(x*1.2, y*1.2, X.columns[i], color=color, ha='center', va='center', fontsize=12)\n",
        "\n",
        "# Set the axis limits\n",
        "plt.xlim(-1, 1)\n",
        "plt.ylim(-1, 1)\n",
        "\n",
        "# Set the axis labels\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K8QVsOu0Rv3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WPhqD3fgR1MX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}